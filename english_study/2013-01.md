### 2013-01-07

If you use PyMongo, 10gen's official MongoDB driver for Python, I want to ensure you understand how it manages sockets and threads, and I want to brag about performance improvements in PyMongo 2.2, which we plan to release next week.

- improvements : 提高，改进

Each PyMongo Connection object includes a connection pool (a pool of sockets) to minimize the cost of reconnecting. If you do two operations (e.g., two find()s) on a Connection, it creates a socket for the first find(), then reuses that socket for the second.

- minimize: 最小化

When sockets are returned to the pool, the pool checks if it has more than max_pool_size spare sockets, and if so, it closes the extra sockets. By default max_pool_size is 10.

- extra: 额外的

What if multiple Python threads share a Connection? A possible implementation would be for each thread to get a random socket from the pool when needed, and return it when done. But consider the following code. It updates a count of visitors to a web page, then displays the number of visitors on that web page including this visit:

- implementation: 方法，实现方法
- consider：考虑
- visitors：访问者

Since PyMongo defaults to unsafe writes—that is, it does not ask the server to acknowledge its inserts and updates—it will send the update message to the server and then instantly send the find_one, then await the result. If PyMongo gave out sockets to threads at random, then the following sequence could occur:

- Since: 因为
- acknowledge: 承认，告知收到
- instantly: 立即
- gave out: 公布，发表
- occur: 发生

This thread gets a socket, which I'll call socket 1, from the pool.
The thread sends the update message to MongoDB on socket 1. The thread does not ask for nor await a response.
The thread returns socket 1 to the pool.
The thread asks for a socket again, and gets a different one: socket 2.
The thread sends the find_one message to MongoDB on socket 2.
MongoDB happens to read from socket 2 first, and executes the find_one.
Finally, MongoDB reads the update message from socket 1 and executes it.

- executes:执行

In this case, the count displayed to the visitor wouldn't include this visit.

I know what you're thinking: just do the find_one first, add one to it, and display it to the user. Then send the update to MongoDB to increment the counter. Or use findAndModify to update the counter and get its new value in one round trip. Those are great solutions, but then I would have no excuse to explain requests to you.

- trip: 旅程
- excuse: 成为...的理由，原谅
- explain: 说明，阐明，解释

Maybe you're thinking of a different fix: use update(safe=True). That would work, as well, with the added advantage that you'd know if the update failed, for example because MongoDB's disk is full, or you violated a unique index. But a safe update comes with a latency cost: you must send the update, wait for the acknowledgement, then send the find_one and wait for the response. In a tight loop the extra latency is significant.

- advantage: 优点，长处，优势
- violated: 违反
- latency: 潜伏，潜在
- tight: 紧密的
- significant: 重大的，有意义的

PyMongo solves this problem by automatically assigning a socket to each thread, when the thread first requests one. The socket is stored in a thread-local variable within the connection pool. Since MongoDB processes messages on any single socket in order, using a single socket per thread guarantees that in our example code, update is processed before find_one, so find_one's result includes the current visit.

- solves: 解释，说明
- automatically: 自动


### 2013-01-11

I sometimes peruse the ReST questions of stackoverflow.com. Many times I see questions about authentication. There are many options (Basic HTTP Auth, Digest HTTP Auth, OAuth, OAuth Wrap, etc.) however when security is of importance, I like to recommend client side certificates. This is the route our team at ShowClix chose when implementing our API.

- peruse: 熟读，精读
- importance: 重要性

When first implementing the API Authentication, we were using Apache for our ReST API Servers. It took some serious google-fu and tinkering to get Apache cooperating with the client-side certs and passing that info into our PHP App layer. I remember it being a semi-painful process.

- serious：重大的，危险的
- tinkering: 拙劣的工人，拙劣的修整
- cooperating: 合作，配合

Lately, I've become a huge fan of nginx. Its clean, familiar config syntax and speed make it a great alternative for Apache in many cases. Its reverse proxy capabilities are quite nice as well. So, I thought I'd give client-side cert authentication a shot in nginx. Whereas a quick search for "Client Side Certs in Apache" yielded a few relevant results, a similar search for nginx yielded no results, so I figured I'd share here.

- Lately: 近来
- alternative: 办法，出路
- capabilities: 能力，才能
- Whereas: 然而
- relevant: 有关的A
- figured：标明数字的，图解的


Creating and Signing Your Certs

- Signing: 电子签名

This is SSL, so you'll need an cert-key pair for you/the server, the api users/the client and a CA pair. You will be the CA in this case (usually a role played by VeriSign, thawte, GoDaddy, etc.), signing your client's certs. There are plenty of tutorials out there on creating and signing certificates, so I'll leave the details on this to someone else and just quickly show a sample here to give a complete tutorial. NOTE: This is just a quick sample of creating certs and not intended for production.

- plenty: 丰富的，充分的
- tutorials: 指南

# Create the CA Key and Certificate for signing Client Certs

# We're self signing our own server cert here.  This is a no-no in production.

### 2013-01-11

The libevent API provides a mechanism to execute a callback function when a specific event occurs on a file descriptor or after a timeout has been reached. Furthermore, libevent also support callbacks due to signals or regular timeouts.
libevent is meant to replace the event loop found in event driven network servers. An application just needs to call event_dispatch() and then add or remove events dynamically without having to change the event loop.

- mechanism: 设备，机构，结构
- reached: 能够到的范围
- Furthermore: 此外
- dynamically 动态的

Currently, libevent supports /dev/poll, kqueue(2), event ports, POSIX select(2), Windows select(), poll(2), and epoll(4). The internal event mechanism is completely independent of the exposed event API, and a simple update of libevent can provide new functionality without having to redesign the applications. As a result, Libevent allows for portable application development and provides the most scalable event notification mechanism available on an operating system. Libevent can also be used for multi-threaded applications, either by isolating each event_base so that only a single thread accesses it, or by locked access to a single shared event_base. Libevent should compile on Linux, *BSD, Mac OS X, Solaris, Windows, and more.

- Currently: 当前
- independent: 独立的，自主的
- exposed: 无掩藏的,暴露的，显露的
- portable: 便携式的

Libevent additionally provides a sophisticated framework for buffered network IO, with support for sockets, filters, rate-limiting, SSL, zero-copy file transmission, and IOCP. Libevent includes support for several useful protocols, including DNS, HTTP, and a minimal RPC framework.

More information about event notification mechanisms for network servers can be found on Dan Kegel's "The C10K problem" web page.

- sophisticated: 复杂的，尖端的，高端的，微妙的

Standard usage

Every program that uses Libevent must inclurde the <event2/event.h> header, and pass the -levent flag to the linker. (You can instead link -levent_core if you only want the main event and buffered IO-based code, and don't want to link any protocol code.)

Library setup

Before you call any other Libevent functions, you need to set up the library. If you're going to use Libevent from multiple threads in a multithreaded application, you need to initialize thread support -- typically by using evthread_use_pthreads() or evthread_use_windows_threads(). See <event2/thread.h> for more information.

This is also the point where you can replace Libevent's memory management functions with event_set_mem_functions, and enable debug mode with event_enable_debug_mode().

- typically: 往往，典型的

Creating an event base

Next, you need to create an event_base structure, using event_base_new() or event_base_new_with_config(). The event_base is responsible for keeping track of which events are "pending" (that is to say, being watched to see if they become active) and which events are "active". Every event is associated with a single event_base.

- responsible: 负责任的，可靠的
- associated: 发生联系,:TODO

Event notification

For each file descriptor that you wish to monitor, you must create an event structure with event_new(). (You may also declare an event structure and call event_assign() to initialize the members of the structure.) To enable notification, you add the structure to the list of monitored events by calling event_add(). The event structure must remain allocated as long as it is active, so it should generally be allocated on the heap.


Dispaching evets.

Finally, you call event_base_dispatch() to loop and dispatch events. You can also use event_base_loop() for more fine-grained control.

Currently, only one thread can be dispatching a given event_base at a time. If you want to run events in multiple threads at once, you can either have a single event_base whose events add work to a work queue, or you can create multiple event_base objects.

- grained：颗粒的
- at a time: 一次

I/O Buffers

Libevent provides a buffered I/O abstraction on top of the regular event callbacks. This abstraction is called a bufferevent. A bufferevent provides input and output buffers that get filled and drained automatically. The user of a buffered event no longer deals directly with the I/O, but instead is reading from input and writing to output buffers.

Once initialized via bufferevent_socket_new(), the bufferevent structure can be used repeatedly with bufferevent_enable() and bufferevent_disable(). Instead of reading and writing directly to a socket, you would call bufferevent_read() and bufferevent_write().

When read enabled the bufferevent will try to read from the file descriptor and call the read callback. The write callback is executed whenever the output buffer is drained below the write low watermark, which is 0 by default.

See <event2/bufferevent*.h> for more information.

- abstraction: 抽象
- drained: 排水的，排干的
